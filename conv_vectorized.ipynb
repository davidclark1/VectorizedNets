{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'nice_layers' from '/home/davidclark/Projects/VectorizedNets/nice_layers.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from imp import reload\n",
    "import nice_layers as vnn\n",
    "reload(vnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_outer_product(x1, x2, kernel_size):\n",
    "    #assumes stride, padding, dilation are all defaults!\n",
    "    #x1 = (batch_size, in_channels, h_in, w_in)\n",
    "    #x2 = (batch_size, out_channels, h_out, w_out)\n",
    "    #out = (batch_size, out_chanels, in_channels, kernel_size, kernel_size)\n",
    "    \n",
    "    batch_size = x1.shape[0]\n",
    "    if x2.shape[0] != batch_size:\n",
    "        raise ValueError(\"x1 and x2 must have the same batch size\")\n",
    "    in_channels = x1.shape[1]\n",
    "    out_channels = x2.shape[1]\n",
    "    h_in, w_in = x1.shape[2:]\n",
    "    h_out, w_out = x2.shape[2:]\n",
    "    \n",
    "    w_out_expected = w_in - kernel_size + 1\n",
    "    h_out_expected = h_in - kernel_size + 1\n",
    "    if (h_out_expected != h_out) or (w_out_expected != w_out):\n",
    "        raise ValueError(\"invalid kernel size\")\n",
    "\n",
    "    x1_prime = x1.permute(1, 0, 2, 3)\n",
    "    x2_prime = x2.view(batch_size*out_channels, h_out, w_out).unsqueeze(1)\n",
    "    out_prime = F.conv2d(input=x1_prime, weight=x2_prime, groups=batch_size)\n",
    "    out = out_prime.view(in_channels, batch_size, out_channels, kernel_size, kernel_size).permute(1, 2, 0, 3, 4)\n",
    "    return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 3, 5, 7, 7])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.randn(256, 5, 28, 28)\n",
    "x2 = torch.randn(256, 3, 22, 22)\n",
    "\n",
    "out = convolutional_outer_product(x1, x2, 7)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(968.) 968\n",
      "tensor(1936.) 1936\n",
      "tensor(2904.) 2904\n",
      "tensor(3872.) 3872\n",
      "tensor(1936.) 1936\n",
      "tensor(3872.) 3872\n",
      "tensor(5808.) 5808\n",
      "tensor(7744.) 7744\n",
      "tensor(2904.) 2904\n",
      "tensor(5808.) 5808\n",
      "tensor(8712.) 8712\n",
      "tensor(11616.) 11616\n",
      "tensor(3872.) 3872\n",
      "tensor(7744.) 7744\n",
      "tensor(11616.) 11616\n",
      "tensor(15488.) 15488\n",
      "tensor(4840.) 4840\n",
      "tensor(9680.) 9680\n",
      "tensor(14520.) 14520\n",
      "tensor(19360.) 19360\n"
     ]
    }
   ],
   "source": [
    "for i in range(out_channels):\n",
    "    for j in range(in_channels):\n",
    "        res = out[-1, i, j]\n",
    "        target = 2*(i+1)*(j+1)*22*22\n",
    "        print(res[0, 0], target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 10, 50])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(256, 10, 150)\n",
    "output = model(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): VecLinear()\n",
       "  (1): VecLinear()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(vnn)\n",
    "\n",
    "model = nn.Sequential(vnn.Conv2d(10, 30, 6, 5),\n",
    "                      vnn.tReLU(),\n",
    "                      vnn.AvgPool2d(2),\n",
    "                      vnn.Conv2d(10, 6, 16, 5),\n",
    "                      vnn.tReLU(),\n",
    "                      vnn.AvgPool2d(2),\n",
    "                      vnn.Conv2d(10, 16, 120, 5),\n",
    "                      vnn.tReLU(),\n",
    "                      vnn.Flatten(),\n",
    "                      vnn.Linear(10, 120, 84),\n",
    "                      vnn.tReLU(),\n",
    "                      vnn.Dropout(),\n",
    "                      vnn.Linear(10, 84, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 10, 30, 32, 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiated t with shape (10, 6, 28, 28)\n",
      "Instantiated t with shape (10, 16, 10, 10)\n",
      "Instantiated t with shape (10, 120, 1, 1)\n",
      "Instantiated t with shape (10, 84)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 1])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in model: module.post_step_callback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 0., 0.],\n",
       "        [2., 2., 2.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [2., 0., 2.]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do = nn.Dropout(p=0.5)\n",
    "x = torch.ones(5, 3)\n",
    "do(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(nn.Module):\n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "    def forward(self, input):\n",
    "        if self.training:\n",
    "            mask_shape = (input.shape[0],) + input.shape[2:]\n",
    "            mask = (torch.rand(mask_shape, device=input.device) > self.p).float()\n",
    "            output = input * mask[:, None] * (1. / (1. - self.p))\n",
    "            return output\n",
    "        else:\n",
    "            return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0., 10.,  0.,  0.,  0.],\n",
       "         [ 0., 10.,  0.,  0.,  0.],\n",
       "         [ 0., 10.,  0.,  0.,  0.],\n",
       "         [ 0., 10.,  0.,  0.,  0.],\n",
       "         [ 0., 10.,  0.,  0.,  0.],\n",
       "         [ 0., 10.,  0.,  0.,  0.],\n",
       "         [ 0., 10.,  0.,  0.,  0.],\n",
       "         [ 0., 10.,  0.,  0.,  0.],\n",
       "         [ 0., 10.,  0.,  0.,  0.],\n",
       "         [ 0., 10.,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0., 10.],\n",
       "         [ 0.,  0.,  0.,  0., 10.],\n",
       "         [ 0.,  0.,  0.,  0., 10.],\n",
       "         [ 0.,  0.,  0.,  0., 10.],\n",
       "         [ 0.,  0.,  0.,  0., 10.],\n",
       "         [ 0.,  0.,  0.,  0., 10.],\n",
       "         [ 0.,  0.,  0.,  0., 10.],\n",
       "         [ 0.,  0.,  0.,  0., 10.],\n",
       "         [ 0.,  0.,  0.,  0., 10.],\n",
       "         [ 0.,  0.,  0.,  0., 10.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.]]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do = Dropout(p=0.9)\n",
    "x = torch.ones(3, 10, 5)\n",
    "do.train()\n",
    "do(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 2., 2., 2., 2.],\n",
       "         [0., 2., 2., 2., 2.],\n",
       "         [0., 2., 2., 2., 2.],\n",
       "         [0., 2., 2., 2., 2.],\n",
       "         [0., 2., 2., 2., 2.],\n",
       "         [0., 2., 2., 2., 2.],\n",
       "         [0., 2., 2., 2., 2.],\n",
       "         [0., 2., 2., 2., 2.],\n",
       "         [0., 2., 2., 2., 2.],\n",
       "         [0., 2., 2., 2., 2.]],\n",
       "\n",
       "        [[0., 2., 0., 0., 0.],\n",
       "         [0., 2., 0., 0., 0.],\n",
       "         [0., 2., 0., 0., 0.],\n",
       "         [0., 2., 0., 0., 0.],\n",
       "         [0., 2., 0., 0., 0.],\n",
       "         [0., 2., 0., 0., 0.],\n",
       "         [0., 2., 0., 0., 0.],\n",
       "         [0., 2., 0., 0., 0.],\n",
       "         [0., 2., 0., 0., 0.],\n",
       "         [0., 2., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 2., 2., 2.],\n",
       "         [0., 0., 2., 2., 2.],\n",
       "         [0., 0., 2., 2., 2.],\n",
       "         [0., 0., 2., 2., 2.],\n",
       "         [0., 0., 2., 2., 2.],\n",
       "         [0., 0., 2., 2., 2.],\n",
       "         [0., 0., 2., 2., 2.],\n",
       "         [0., 0., 2., 2., 2.],\n",
       "         [0., 0., 2., 2., 2.],\n",
       "         [0., 0., 2., 2., 2.]]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
