{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from imp import reload\n",
    "import torch.nn as nn\n",
    "\n",
    "import vnn2\n",
    "reload(vnn2)\n",
    "import local2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 4\n",
    "out_channels = 4\n",
    "h_in = 24\n",
    "w_in = 24\n",
    "kernel_size = 5\n",
    "\n",
    "lc = local2d.Local2d(in_channels, out_channels, kernel_size, h_in, w_in, stride=1, padding=3, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(128, in_channels, h_in, w_in)\n",
    "out = lc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = out.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = lc.weight.grad.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = lc.weight.detach().clone()\n",
    "W.grad = None\n",
    "W.requires_grad = True\n",
    "out = local2d.lc_forward(x.clone(), W, stride=1, padding=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = out.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2 = W.grad.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1444e-05)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(g1-g2).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(vnn2)\n",
    "def make_mnist_vec_lc(mono=False):\n",
    "    model = nn.Sequential(\n",
    "        vnn2.VecLocal2d(10, 10, 32, 3, h_in=28, w_in=28, stride=1, padding=1, first_layer=True, mono=mono),\n",
    "        vnn2.ctReLU(10, 32, 28, 28),\n",
    "        vnn2.AvgPool2d(2),\n",
    "        vnn2.VecLocal2d(10, 32, 32, 3, h_in=14, w_in=14, stride=1, padding=1, mono=mono),\n",
    "        vnn2.ctReLU(10, 32, 14, 14),\n",
    "        vnn2.AvgPool2d(2), #7 by 7\n",
    "        vnn2.Flatten(),\n",
    "        vnn2.Linear(10, 1568, 1024, mono=mono),\n",
    "        vnn2.tReLU(10, 1024),\n",
    "        vnn2.Linear(10, 1024, 1, mono=mono))\n",
    "    return model\n",
    "\n",
    "def make_cifar_vec_lc(mono=False):\n",
    "    model = nn.Sequential(\n",
    "        vnn2.VecLocal2d(10, 30, 128, 5, h_in=32, w_in=32, stride=1, padding=2, first_layer=True, mono=mono),\n",
    "        vnn2.ctReLU(10, 128, 32, 32),\n",
    "        vnn2.AvgPool2d(2),\n",
    "        vnn2.VecLocal2d(10, 128, 128, 5, h_in=16, w_in=16, stride=1, padding=2, mono=mono),\n",
    "        vnn2.ctReLU(10, 128, 16, 16),\n",
    "        vnn2.AvgPool2d(2),\n",
    "        vnn2.VecLocal2d(10, 128, 128, 2, h_in=8, w_in=8, stride=2, padding=0, mono=mono),\n",
    "        vnn2.ctReLU(10, 128, 4, 4),\n",
    "        vnn2.Flatten(),\n",
    "        vnn2.Linear(10, 2048, 1024, mono=mono),\n",
    "        vnn2.tReLU(10, 1024),\n",
    "        vnn2.Linear(10, 1024, 1, mono=mono))\n",
    "    return model\n",
    "\n",
    "model = make_mnist_vec_lc(mono=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(64, 10, 10, 28, 28).to(0)\n",
    "labels = torch.randint(0, 10, (64,)).to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A torch.Size([640, 10, 28, 28])\n",
      "B torch.Size([640, 10, 30, 30])\n",
      "torch.Size([64, 10, 32, 28, 28])\n",
      "torch.Size([64, 10, 32, 28, 28])\n",
      "A torch.Size([640, 32, 14, 14])\n",
      "B torch.Size([640, 32, 16, 16])\n",
      "torch.Size([64, 10, 32, 14, 14])\n",
      "torch.Size([64, 10, 32, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "reload(vnn2)\n",
    "output = model(input)[..., 0]\n",
    "vnn2.set_model_grads(model, output, labels, learning_rule=\"bp\", reduction=\"mean\")\n",
    "g1 = [param.grad for (name, param) in model.named_parameters() if name[-2:] != \".t\"]\n",
    "#22s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A torch.Size([640, 10, 28, 28])\n",
      "B torch.Size([640, 10, 30, 30])\n",
      "torch.Size([64, 10, 32, 28, 28])\n",
      "torch.Size([64, 10, 32, 28, 28])\n",
      "A torch.Size([640, 32, 14, 14])\n",
      "B torch.Size([640, 32, 16, 16])\n",
      "torch.Size([64, 10, 32, 14, 14])\n",
      "torch.Size([64, 10, 32, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "for (name, param) in model.named_parameters():\n",
    "    if name[-2:] != \".t\":\n",
    "        param.grad = None\n",
    "        param.requires_grad = True\n",
    "output = model(input)[..., 0]\n",
    "loss = loss_fn(output, labels)\n",
    "loss.backward()\n",
    "g2 = [param.grad for (name, param) in model.named_parameters() if name[-2:] != \".t\"]\n",
    "#44 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(6.1118e-10, device='cuda:0'),\n",
       " tensor(1.8917e-10, device='cuda:0'),\n",
       " tensor(4.6566e-09, device='cuda:0'),\n",
       " tensor(9.8953e-10, device='cuda:0'),\n",
       " tensor(1.8626e-08, device='cuda:0'),\n",
       " tensor(1.1642e-09, device='cuda:0'),\n",
       " tensor(4.4703e-08, device='cuda:0'),\n",
       " tensor(7.4506e-09, device='cuda:0')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(g1[i]-g2[i]).abs().max() for i in range(len(g1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9999999999998788, 0.0),\n",
       " (0.9999999999998812, 0.0),\n",
       " (0.999999999999877, 0.0),\n",
       " (0.9999999999998916, 0.0),\n",
       " (0.9999999999999359, 0.0),\n",
       " (0.999999999999995, 0.0),\n",
       " (0.9999999999999892, 0.0),\n",
       " (0.9999999999999925, 1.4211981301389257e-56)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "[pearsonr(g1[i].cpu().flatten().numpy(), g2[i].cpu().flatten().numpy()) for i in range(len(g1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(diff, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = g1[5].numpy().flatten()\n",
    "b = g2[5].numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999999999999624, 0.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight\n",
      "0.bias\n",
      "1.t\n",
      "3.weight\n",
      "3.bias\n",
      "4.t\n",
      "6.weight\n",
      "6.bias\n",
      "7.t\n",
      "9.weight\n",
      "9.bias\n",
      "10.t\n",
      "11.weight\n",
      "11.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
