{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "np.random.seed(42)\n",
    "PERMUTATIONS = [np.random.permutation(784) for _ in range(10)]\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90, 8, 7, 6])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn(10, 9, 8, 7, 6)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(9):\n",
    "        A[i, j] = i*9 + j\n",
    "        \n",
    "        \n",
    "B = A.view((A.shape[0]*A.shape[1],) + A.shape[2:])\n",
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.]],\n",
       "\n",
       "        [[87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.]],\n",
       "\n",
       "        [[87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.]],\n",
       "\n",
       "        [[87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.]],\n",
       "\n",
       "        [[87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.]],\n",
       "\n",
       "        [[87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.]],\n",
       "\n",
       "        [[87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.]],\n",
       "\n",
       "        [[87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.],\n",
       "         [87., 87., 87., 87., 87., 87.]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvVectorizedLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, category_dim, stride=1, padding=0, dilation=1,\n",
    "                 groups=1, padding_mode='zeros', nonneg=False, nonlin=True, expanded_input=False, pool=True, pool_size=2, pool_stride=2):\n",
    "        super(ConvVectorizedLayer, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias=False, padding_mode=padding_mode)\n",
    "        \n",
    "        k = groups / (in_channels * np.prod(kernel_size))\n",
    "        if expanded_input:\n",
    "            k = k * category_dim\n",
    "        with torch.no_grad():\n",
    "            if nonneg: self.conv.weight.uniform_(0, np.sqrt(k))\n",
    "            else: self.conv.weight.uniform_(-np.sqrt(k), np.sqrt(k))\n",
    "        self.bias = nn.Parameter(torch.zeros(category_dim, out_channels))\n",
    "        \n",
    "        if pool:\n",
    "            self.avgpool = nn.AvgPool2d(kernel_size=pool_size, stride=pool_stride)\n",
    "        \n",
    "        \n",
    "        self.pool = pool\n",
    "        self.nonneg = nonneg\n",
    "        self.nonlin = nonlin\n",
    "        \n",
    "    def forward(self, input):\n",
    "        #(batch_dim, category_dim, channels, width, height)\n",
    "        input_reshaped = input.view((input.shape[0]*input.shape[1],) + input.shape[2:])\n",
    "        conv_out = self.conv(input_reshaped)\n",
    "        saved_shape = conv_out.shape\n",
    "        conv_out = conv_out.view((input.shape[0], input.shape[1]) + conv_out.shape[1:]) #?\n",
    "        conv_out = conv_out + self.bias[None, :, :, None, None]\n",
    "        if self.nonlin:\n",
    "            conv_out_sum = conv_out.sum(dim=1).detach()\n",
    "            mask = (conv_out_sum > 0.).float()\n",
    "            conv_out = conv_out * mask[:, None, :, :, :]\n",
    "        if self.pool:\n",
    "            conv_out = conv_out.view(saved_shape)\n",
    "            conv_out = self.avgpool(conv_out)\n",
    "            conv_out = conv_out.view((input.shape[0], input.shape[1]) + conv_out.shape[1:])\n",
    "        return conv_out\n",
    "    \n",
    "    def post_step_callback(self):\n",
    "        if self.nonneg:\n",
    "            with torch.no_grad():\n",
    "                self.conv.weight.clamp_(min=0)\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = ConvVectorizedLayer(in_channels=10, out_channels=3, kernel_size=6,\n",
    "                           category_dim=10, nonneg=True, nonlin=True, pool=True, pool_size=3, pool_stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_input(input, category_dim):\n",
    "    #input = (batch, channels, width, height)\n",
    "    batch_size, in_channels = input.shape[:2]\n",
    "    expanded_input = torch.zeros((batch_size,) + (category_dim,) + (in_channels*category_dim,) + input.shape[2:])\n",
    "    for i in range(category_dim):\n",
    "        expanded_input[:, i, i*in_channels:(i+1)*in_channels] = input\n",
    "    return expanded_input\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'layers' from '/home/davidclark/Projects/VectorizedNets/layers.py'>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import layers\n",
    "from imp import reload\n",
    "reload(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorizedLeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_part = nn.Sequential(ConvVectorizedLayer(30, 6, 5, 10, expanded_input=True, nonlin=True, nonneg=False),\n",
    "                                  ConvVectorizedLayer(6, 16, 5, 10, nonlin=True, nonneg=False),\n",
    "                                  ConvVectorizedLayer(16, 120, 5, 10, nonlin=True, pool=False, nonneg=False))\n",
    "        self.fc_part = nn.Sequential(layers.VectorizedLayer(120, 84, 10, nonneg=False, nonlin=True),\n",
    "                                layers.VectorizedLayer(84, 1, 10, nonneg=False, nonlin=False))\n",
    "        \n",
    "    def post_step_callback(self):\n",
    "        for i in range(len(self.conv_part)):\n",
    "            self.conv_part[i].post_step_callback()\n",
    "        for i in range(len(self.fc_part)):\n",
    "            self.fc_part[i].post_step_callback()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        conv_out = self.conv_part(input)\n",
    "        conv_out = conv_out.view(conv_out.shape[:2] + (120,))\n",
    "        fc_out = self.fc_part(conv_out)\n",
    "        return fc_out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(128, 10, 30, 32, 32)\n",
    "\n",
    "model = VectorizedLeNet()\n",
    "\n",
    "#model(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "train_set = torchvision.datasets.CIFAR10(\"./data\", train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.CIFAR10(\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(0.1172)\n",
      "tensor(0.1328)\n",
      "tensor(0.1250)\n",
      "tensor(0.1172)\n",
      "tensor(0.1250)\n",
      "tensor(0.1094)\n",
      "tensor(0.0703)\n",
      "tensor(0.1719)\n",
      "tensor(0.1328)\n",
      "tensor(0.1250)\n",
      "tensor(0.1328)\n",
      "tensor(0.1641)\n",
      "tensor(0.1406)\n",
      "tensor(0.1484)\n",
      "tensor(0.1562)\n",
      "tensor(0.1172)\n",
      "tensor(0.1328)\n",
      "tensor(0.1641)\n",
      "tensor(0.1641)\n",
      "tensor(0.1719)\n",
      "tensor(0.1016)\n",
      "tensor(0.1484)\n",
      "tensor(0.1797)\n",
      "tensor(0.1641)\n",
      "tensor(0.1172)\n",
      "tensor(0.1953)\n",
      "tensor(0.1562)\n",
      "tensor(0.1484)\n",
      "tensor(0.1406)\n",
      "tensor(0.1875)\n",
      "tensor(0.1797)\n",
      "tensor(0.1953)\n",
      "tensor(0.1250)\n",
      "tensor(0.1406)\n",
      "tensor(0.1484)\n",
      "tensor(0.1562)\n",
      "tensor(0.1875)\n",
      "tensor(0.2266)\n",
      "tensor(0.1641)\n",
      "tensor(0.1562)\n",
      "tensor(0.1562)\n",
      "tensor(0.1562)\n",
      "tensor(0.1484)\n",
      "tensor(0.1328)\n",
      "tensor(0.1641)\n",
      "tensor(0.1484)\n",
      "tensor(0.2109)\n",
      "tensor(0.1562)\n",
      "tensor(0.1484)\n",
      "tensor(0.2188)\n",
      "tensor(0.2109)\n",
      "tensor(0.1328)\n",
      "tensor(0.1797)\n",
      "tensor(0.1562)\n",
      "tensor(0.1641)\n",
      "tensor(0.1406)\n",
      "tensor(0.1172)\n",
      "tensor(0.1797)\n",
      "tensor(0.1562)\n",
      "tensor(0.1875)\n",
      "tensor(0.1484)\n",
      "tensor(0.2344)\n",
      "tensor(0.1797)\n",
      "tensor(0.1562)\n",
      "tensor(0.2109)\n",
      "tensor(0.1562)\n",
      "tensor(0.1484)\n",
      "tensor(0.1328)\n",
      "tensor(0.1719)\n",
      "tensor(0.1797)\n",
      "tensor(0.1562)\n",
      "tensor(0.1641)\n",
      "tensor(0.1250)\n",
      "tensor(0.1484)\n",
      "tensor(0.1250)\n",
      "tensor(0.1875)\n",
      "tensor(0.1875)\n",
      "tensor(0.1484)\n",
      "tensor(0.1875)\n",
      "tensor(0.1875)\n",
      "tensor(0.1484)\n",
      "tensor(0.1719)\n",
      "tensor(0.2031)\n",
      "tensor(0.2578)\n",
      "tensor(0.1875)\n",
      "tensor(0.1641)\n",
      "tensor(0.1719)\n",
      "tensor(0.1719)\n",
      "tensor(0.2031)\n",
      "tensor(0.1797)\n",
      "tensor(0.1875)\n",
      "tensor(0.1641)\n",
      "tensor(0.1719)\n",
      "tensor(0.1719)\n",
      "tensor(0.1250)\n",
      "tensor(0.1719)\n",
      "tensor(0.1719)\n",
      "tensor(0.1250)\n",
      "tensor(0.1172)\n",
      "tensor(0.1562)\n",
      "tensor(0.1797)\n",
      "tensor(0.2031)\n",
      "tensor(0.1953)\n",
      "tensor(0.1172)\n",
      "tensor(0.1719)\n",
      "tensor(0.1953)\n",
      "tensor(0.1719)\n",
      "tensor(0.1250)\n",
      "tensor(0.2266)\n",
      "tensor(0.1406)\n",
      "tensor(0.1250)\n",
      "tensor(0.1641)\n",
      "tensor(0.1406)\n",
      "tensor(0.1641)\n",
      "tensor(0.1641)\n",
      "tensor(0.1641)\n",
      "tensor(0.1875)\n",
      "tensor(0.2188)\n",
      "tensor(0.2500)\n",
      "tensor(0.1406)\n",
      "tensor(0.2109)\n",
      "tensor(0.1484)\n",
      "tensor(0.2344)\n",
      "tensor(0.2031)\n",
      "tensor(0.2578)\n",
      "tensor(0.2109)\n",
      "tensor(0.2500)\n",
      "tensor(0.1797)\n",
      "tensor(0.1797)\n",
      "tensor(0.1328)\n",
      "tensor(0.2109)\n",
      "tensor(0.1953)\n",
      "tensor(0.2266)\n",
      "tensor(0.1719)\n",
      "tensor(0.2109)\n",
      "tensor(0.1719)\n",
      "tensor(0.2422)\n",
      "tensor(0.1875)\n",
      "tensor(0.2031)\n",
      "tensor(0.2031)\n",
      "tensor(0.1953)\n",
      "tensor(0.1641)\n",
      "tensor(0.1797)\n",
      "tensor(0.2266)\n",
      "tensor(0.1953)\n",
      "tensor(0.2422)\n",
      "tensor(0.2188)\n",
      "tensor(0.1641)\n",
      "tensor(0.2031)\n",
      "tensor(0.1875)\n",
      "tensor(0.2266)\n",
      "tensor(0.2500)\n",
      "tensor(0.1875)\n",
      "tensor(0.1797)\n",
      "tensor(0.2969)\n",
      "tensor(0.2031)\n",
      "tensor(0.1953)\n",
      "tensor(0.1406)\n",
      "tensor(0.1875)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-17b13727b6e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-ace0e6e773ce>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mconv_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_part\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mconv_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mfc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_part\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-95211fba9388>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#(batch_dim, category_dim, channels, width, height)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0minput_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mconv_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0msaved_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mconv_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconv_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    413\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 415\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    416\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = VectorizedLeNet()\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch_idx in range(1000):\n",
    "    print(epoch_idx)\n",
    "    epoch_loss = 0.\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        input = expand_input(data, 10)\n",
    "        out = model(input)[..., 0]\n",
    "        loss = loss_fn(out, labels)\n",
    "        epoch_loss += loss.item()\n",
    "        acc = (out.detach().argmax(dim=1) == labels).float().mean()\n",
    "        print(acc)\n",
    "        #optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #model.post_step_callback()\n",
    "    print(epoch_loss / (batch_idx + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 3.8833e-01,  2.5953e-01,  2.9085e-01,  3.6096e-01,  3.4685e-01],\n",
       "          [ 3.1685e-02, -1.3424e-01, -8.6265e-02,  4.4567e-02,  9.5919e-02],\n",
       "          [-1.4994e-01, -3.2541e-01, -3.0814e-01, -1.9294e-01, -1.3343e-01],\n",
       "          [-2.0272e-01, -3.5444e-01, -3.8051e-01, -2.9681e-01, -2.7025e-01],\n",
       "          [-3.0795e-01, -4.4734e-01, -4.7512e-01, -3.8065e-01, -3.4627e-01]],\n",
       "\n",
       "         [[ 4.8603e-01,  3.2542e-01,  3.2897e-01,  3.9225e-01,  3.8920e-01],\n",
       "          [ 1.2913e-01, -6.9508e-02, -4.6146e-02,  7.8796e-02,  1.4004e-01],\n",
       "          [-6.6802e-02, -2.7440e-01, -2.7874e-01, -1.7278e-01, -1.1063e-01],\n",
       "          [-1.5374e-01, -3.3059e-01, -3.7922e-01, -3.0701e-01, -2.8014e-01],\n",
       "          [-3.0846e-01, -4.6694e-01, -5.1109e-01, -4.1700e-01, -3.7184e-01]],\n",
       "\n",
       "         [[ 2.9880e-01,  1.5014e-01,  1.5748e-01,  2.3186e-01,  2.3975e-01],\n",
       "          [ 1.1446e-02, -1.7486e-01, -1.4560e-01, -1.2637e-02,  4.5705e-02],\n",
       "          [-1.3347e-01, -3.2964e-01, -3.3304e-01, -2.2949e-01, -1.7978e-01],\n",
       "          [-2.0090e-01, -3.7130e-01, -4.2770e-01, -3.6041e-01, -3.3603e-01],\n",
       "          [-3.6491e-01, -5.1290e-01, -5.6338e-01, -4.7073e-01, -4.1804e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.8433e-02,  1.5844e-01,  3.8659e-02, -1.5748e-01, -2.4744e-01],\n",
       "          [-7.8941e-02,  1.2267e-01,  8.2086e-02, -9.8503e-02, -2.5331e-01],\n",
       "          [-2.2482e-01, -2.2150e-02,  7.3645e-03, -8.0391e-02, -1.7428e-01],\n",
       "          [-3.4015e-01, -1.6850e-01, -9.5043e-02, -8.2759e-02, -5.9747e-02],\n",
       "          [-3.2372e-01, -1.8332e-01, -1.0585e-01, -1.1271e-01, -8.8340e-02]],\n",
       "\n",
       "         [[-1.2948e-01,  4.9325e-02, -4.2976e-02, -2.0669e-01, -2.8331e-01],\n",
       "          [-1.0977e-01,  8.2143e-02,  6.7860e-02, -7.7258e-02, -2.2191e-01],\n",
       "          [-1.6387e-01,  1.9225e-02,  6.8821e-02,  1.4950e-02, -7.4462e-02],\n",
       "          [-1.5887e-01, -8.1465e-03,  7.6685e-02,  1.0854e-01,  1.2523e-01],\n",
       "          [-2.5209e-02,  9.8058e-02,  1.7546e-01,  1.7182e-01,  1.8334e-01]],\n",
       "\n",
       "         [[-1.9506e-01, -3.1266e-02, -1.2738e-01, -2.8960e-01, -3.4471e-01],\n",
       "          [-1.3038e-01,  4.2775e-02,  2.2237e-02, -1.2740e-01, -2.5464e-01],\n",
       "          [-1.7905e-01, -1.4766e-02,  3.1019e-02, -2.7866e-02, -9.9536e-02],\n",
       "          [-2.1151e-01, -7.9470e-02,  3.0234e-03,  3.6370e-02,  7.8782e-02],\n",
       "          [-1.2068e-01, -1.3825e-02,  6.3049e-02,  6.7597e-02,  1.1110e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.5979e-01,  6.0365e-01,  5.9781e-01,  4.0171e-01,  4.9739e-01],\n",
       "          [ 4.4305e-01,  9.6113e-01,  1.0825e+00,  8.3272e-01,  8.0327e-01],\n",
       "          [ 3.7843e-01,  8.8155e-01,  9.8492e-01,  6.8558e-01,  5.8732e-01],\n",
       "          [ 2.7122e-01,  6.2803e-01,  6.6774e-01,  3.9906e-01,  2.8356e-01],\n",
       "          [ 3.7358e-01,  6.6948e-01,  6.9672e-01,  4.5943e-01,  3.1517e-01]],\n",
       "\n",
       "         [[ 2.6549e-01,  6.2025e-01,  5.9290e-01,  3.5049e-01,  4.2019e-01],\n",
       "          [ 4.0867e-01,  9.3311e-01,  1.0291e+00,  7.2406e-01,  6.6277e-01],\n",
       "          [ 3.2614e-01,  8.3643e-01,  9.1815e-01,  5.6474e-01,  4.2922e-01],\n",
       "          [ 2.1262e-01,  5.7838e-01,  6.0852e-01,  2.9816e-01,  1.4498e-01],\n",
       "          [ 3.1616e-01,  6.3213e-01,  6.6549e-01,  3.9912e-01,  2.2332e-01]],\n",
       "\n",
       "         [[ 6.0524e-01,  9.3180e-01,  8.5581e-01,  5.6220e-01,  6.3158e-01],\n",
       "          [ 6.3392e-01,  1.1128e+00,  1.1469e+00,  7.8649e-01,  7.2965e-01],\n",
       "          [ 4.6684e-01,  9.4089e-01,  9.7550e-01,  5.8167e-01,  4.5350e-01],\n",
       "          [ 2.8091e-01,  6.4222e-01,  6.5924e-01,  3.2583e-01,  1.6813e-01],\n",
       "          [ 3.1244e-01,  6.3746e-01,  6.7864e-01,  4.0404e-01,  2.2012e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.8968e-02, -3.6855e-01, -3.6596e-01, -8.9276e-02, -2.6006e-01],\n",
       "          [ 8.9073e-02, -3.9262e-01, -4.3165e-01, -7.2210e-02, -1.8530e-01],\n",
       "          [ 4.6003e-02, -4.2991e-01, -3.8083e-01,  7.6166e-02, -1.1671e-02],\n",
       "          [-3.2535e-02, -3.8358e-01, -2.4048e-01,  2.1867e-01,  1.4309e-01],\n",
       "          [-1.2060e-01, -4.2189e-01, -2.7090e-01,  1.2393e-01,  8.6323e-02]],\n",
       "\n",
       "         [[ 1.7221e-01, -2.8340e-01, -3.2825e-01, -5.2330e-02, -2.0252e-01],\n",
       "          [ 2.1791e-01, -3.1859e-01, -4.2029e-01, -6.4300e-02, -1.5756e-01],\n",
       "          [ 1.4512e-01, -3.8247e-01, -4.2151e-01,  2.7002e-02, -4.2172e-02],\n",
       "          [ 3.8691e-02, -3.8388e-01, -3.5337e-01,  8.1893e-02,  2.1940e-02],\n",
       "          [-6.1939e-02, -4.3919e-01, -3.9985e-01, -4.3212e-02, -7.7408e-02]],\n",
       "\n",
       "         [[ 2.3746e-01, -2.4606e-01, -3.4152e-01, -1.1688e-01, -2.3991e-01],\n",
       "          [ 2.9119e-01, -2.7604e-01, -4.3949e-01, -1.4293e-01, -2.0536e-01],\n",
       "          [ 2.8514e-01, -2.6236e-01, -3.6099e-01,  2.6299e-02, -1.4121e-02],\n",
       "          [ 2.8468e-01, -1.3170e-01, -1.4639e-01,  2.3532e-01,  1.9524e-01],\n",
       "          [ 2.8601e-01, -6.5225e-02, -5.4151e-02,  2.5834e-01,  2.2746e-01]]],\n",
       "\n",
       "\n",
       "        [[[-6.4289e-01, -6.2237e-01, -6.3922e-01, -7.0297e-01, -7.2545e-01],\n",
       "          [-5.2095e-01, -4.2862e-01, -4.7618e-01, -6.1168e-01, -6.9911e-01],\n",
       "          [-4.5164e-01, -3.3829e-01, -4.1483e-01, -6.3198e-01, -8.1118e-01],\n",
       "          [-7.2946e-01, -6.5961e-01, -7.3316e-01, -8.9287e-01, -1.0179e+00],\n",
       "          [-9.5632e-01, -9.3018e-01, -9.8889e-01, -1.0630e+00, -1.1019e+00]],\n",
       "\n",
       "         [[-5.5936e-01, -5.3166e-01, -5.3842e-01, -5.9762e-01, -6.2847e-01],\n",
       "          [-3.7479e-01, -2.7993e-01, -3.2130e-01, -4.5681e-01, -5.5631e-01],\n",
       "          [-2.6486e-01, -1.5485e-01, -2.2526e-01, -4.4188e-01, -6.3197e-01],\n",
       "          [-5.1909e-01, -4.5442e-01, -5.1738e-01, -6.7246e-01, -8.0418e-01],\n",
       "          [-7.4941e-01, -7.2540e-01, -7.7501e-01, -8.4454e-01, -8.8892e-01]],\n",
       "\n",
       "         [[-6.7982e-01, -6.4009e-01, -6.4302e-01, -7.0629e-01, -7.4975e-01],\n",
       "          [-4.2688e-01, -3.2807e-01, -3.7121e-01, -5.1156e-01, -6.2357e-01],\n",
       "          [-2.7640e-01, -1.7029e-01, -2.4432e-01, -4.6054e-01, -6.5745e-01],\n",
       "          [-5.1323e-01, -4.5553e-01, -5.2067e-01, -6.7186e-01, -8.0821e-01],\n",
       "          [-7.4430e-01, -7.2561e-01, -7.7890e-01, -8.4893e-01, -8.9734e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.8711e-01,  2.6711e-01,  3.0097e-01,  2.7468e-01,  2.9189e-01],\n",
       "          [ 9.3367e-03,  3.8831e-02,  8.4239e-02,  1.0313e-01,  1.4631e-01],\n",
       "          [-2.1370e-01, -2.1164e-01, -1.5275e-01, -8.2257e-02,  9.0821e-03],\n",
       "          [-2.1652e-01, -2.0941e-01, -1.4297e-01, -8.2975e-02, -1.9836e-02],\n",
       "          [-7.6364e-02, -5.6055e-02,  7.8517e-03,  4.6263e-02,  6.2211e-02]],\n",
       "\n",
       "         [[ 1.7648e-01,  1.9978e-01,  1.7160e-01,  1.1837e-01,  1.4461e-01],\n",
       "          [ 9.2449e-02,  7.1904e-02,  5.3542e-02,  4.1800e-02,  9.5584e-02],\n",
       "          [-1.5852e-02, -5.6597e-02, -6.1761e-02, -2.9839e-02,  6.5761e-02],\n",
       "          [ 4.5167e-02,  9.4380e-03,  9.5073e-03,  3.0923e-02,  1.0069e-01],\n",
       "          [ 1.9833e-01,  1.7355e-01,  1.7896e-01,  1.8814e-01,  2.1572e-01]],\n",
       "\n",
       "         [[ 1.9272e-01,  2.0564e-01,  1.6780e-01,  1.1629e-01,  1.5284e-01],\n",
       "          [ 1.4648e-01,  1.1666e-01,  8.7617e-02,  7.6729e-02,  1.4062e-01],\n",
       "          [ 7.5670e-02,  2.4785e-02,  7.0073e-03,  3.7828e-02,  1.3796e-01],\n",
       "          [ 1.7299e-01,  1.2449e-01,  1.1103e-01,  1.2972e-01,  1.9665e-01],\n",
       "          [ 3.4636e-01,  3.1014e-01,  3.0519e-01,  3.1139e-01,  3.3270e-01]]],\n",
       "\n",
       "\n",
       "        [[[-4.7853e-01, -4.1209e-01, -3.7316e-01, -4.4959e-01, -4.1551e-01],\n",
       "          [-2.7653e-01, -1.8125e-01, -1.4889e-01, -2.5626e-01, -2.7521e-01],\n",
       "          [-1.6356e-01, -9.2411e-02, -1.0440e-01, -2.4649e-01, -2.8779e-01],\n",
       "          [-2.0431e-01, -1.5668e-01, -1.3799e-01, -2.3894e-01, -2.5908e-01],\n",
       "          [-2.0636e-01, -1.6995e-01, -1.4734e-01, -2.4452e-01, -2.5975e-01]],\n",
       "\n",
       "         [[-6.7734e-01, -6.1165e-01, -5.8344e-01, -6.8067e-01, -6.4464e-01],\n",
       "          [-4.7848e-01, -3.8782e-01, -3.6712e-01, -4.9656e-01, -5.1593e-01],\n",
       "          [-3.7042e-01, -3.0355e-01, -3.2476e-01, -4.8370e-01, -5.2659e-01],\n",
       "          [-4.0725e-01, -3.5900e-01, -3.4363e-01, -4.5258e-01, -4.7020e-01],\n",
       "          [-3.8116e-01, -3.4177e-01, -3.1854e-01, -4.1718e-01, -4.2707e-01]],\n",
       "\n",
       "         [[-8.0908e-01, -7.5770e-01, -7.4934e-01, -8.7558e-01, -8.4668e-01],\n",
       "          [-6.4194e-01, -5.6282e-01, -5.5257e-01, -6.9547e-01, -7.1220e-01],\n",
       "          [-5.6727e-01, -5.0434e-01, -5.2002e-01, -6.7530e-01, -7.0774e-01],\n",
       "          [-6.1921e-01, -5.7376e-01, -5.5151e-01, -6.5186e-01, -6.5302e-01],\n",
       "          [-5.9357e-01, -5.6060e-01, -5.3500e-01, -6.2858e-01, -6.1992e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.8813e-01,  5.4910e-01,  3.8828e-01,  3.7993e-01,  2.7851e-01],\n",
       "          [ 7.4076e-01,  5.8108e-01,  4.1275e-01,  4.3445e-01,  3.3279e-01],\n",
       "          [ 7.2263e-01,  5.5209e-01,  3.8346e-01,  4.4094e-01,  3.4715e-01],\n",
       "          [ 6.4210e-01,  5.0668e-01,  3.4256e-01,  3.8257e-01,  2.8864e-01],\n",
       "          [ 5.3963e-01,  4.3616e-01,  2.7535e-01,  2.9112e-01,  1.9077e-01]],\n",
       "\n",
       "         [[ 6.3384e-01,  5.0391e-01,  3.7044e-01,  4.1171e-01,  3.1906e-01],\n",
       "          [ 6.6840e-01,  5.2105e-01,  3.8363e-01,  4.5881e-01,  3.6716e-01],\n",
       "          [ 6.1933e-01,  4.6444e-01,  3.3371e-01,  4.4822e-01,  3.6745e-01],\n",
       "          [ 4.8605e-01,  3.7459e-01,  2.5907e-01,  3.6335e-01,  2.9159e-01],\n",
       "          [ 3.3471e-01,  2.5670e-01,  1.4189e-01,  2.2142e-01,  1.5145e-01]],\n",
       "\n",
       "         [[ 6.2884e-01,  5.0419e-01,  3.7552e-01,  4.0921e-01,  3.1482e-01],\n",
       "          [ 6.4088e-01,  4.9761e-01,  3.6457e-01,  4.3349e-01,  3.4179e-01],\n",
       "          [ 5.8133e-01,  4.2454e-01,  2.9864e-01,  4.0800e-01,  3.2719e-01],\n",
       "          [ 4.5179e-01,  3.3290e-01,  2.2320e-01,  3.2176e-01,  2.4825e-01],\n",
       "          [ 3.0768e-01,  2.2192e-01,  1.1606e-01,  1.9310e-01,  1.2335e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.4190e-01, -3.4367e-01, -4.1292e-01, -3.9436e-01, -2.7892e-01],\n",
       "          [-1.1747e-01, -2.0282e-01, -2.5538e-01, -2.1830e-01, -1.0470e-01],\n",
       "          [ 5.6896e-02,  1.8764e-03, -2.8018e-02,  2.2332e-02,  1.0174e-01],\n",
       "          [ 2.7787e-01,  2.6094e-01,  2.2642e-01,  2.3141e-01,  2.5894e-01],\n",
       "          [ 4.9542e-01,  4.6302e-01,  3.7757e-01,  3.3953e-01,  3.4602e-01]],\n",
       "\n",
       "         [[-4.7085e-01, -5.8083e-01, -6.5624e-01, -6.3814e-01, -5.0716e-01],\n",
       "          [-3.7468e-01, -4.6344e-01, -5.2038e-01, -4.7913e-01, -3.4633e-01],\n",
       "          [-2.3350e-01, -2.9001e-01, -3.1664e-01, -2.5893e-01, -1.5686e-01],\n",
       "          [-4.5078e-02, -6.4434e-02, -9.0107e-02, -7.0342e-02, -1.7656e-02],\n",
       "          [ 1.4691e-01,  1.1287e-01,  3.4624e-02,  1.4845e-02,  5.1602e-02]],\n",
       "\n",
       "         [[-9.0019e-01, -1.0273e+00, -1.1185e+00, -1.1011e+00, -9.4937e-01],\n",
       "          [-8.5290e-01, -9.6638e-01, -1.0460e+00, -1.0047e+00, -8.4445e-01],\n",
       "          [-7.7858e-01, -8.6284e-01, -9.1363e-01, -8.5556e-01, -7.1895e-01],\n",
       "          [-6.5270e-01, -7.0026e-01, -7.4352e-01, -7.1490e-01, -6.2043e-01],\n",
       "          [-4.9783e-01, -5.4962e-01, -6.3487e-01, -6.3786e-01, -5.5930e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.3183e-02,  1.4499e-02,  7.3495e-02,  5.8699e-02,  9.9473e-03],\n",
       "          [ 4.4092e-02,  1.0454e-01,  1.7148e-01,  1.5942e-01,  9.7187e-02],\n",
       "          [ 1.2096e-01,  1.8191e-01,  2.6406e-01,  2.5894e-01,  1.9425e-01],\n",
       "          [ 1.9791e-01,  2.5842e-01,  3.4621e-01,  3.4509e-01,  2.6518e-01],\n",
       "          [ 2.2255e-01,  2.7144e-01,  3.4083e-01,  3.2245e-01,  2.2249e-01]],\n",
       "\n",
       "         [[-4.9770e-02,  7.9102e-03,  6.6388e-02,  4.9246e-02, -1.1281e-02],\n",
       "          [-4.5505e-03,  4.3427e-02,  1.1174e-01,  1.0053e-01,  2.4685e-02],\n",
       "          [ 2.5424e-02,  7.1017e-02,  1.5423e-01,  1.4641e-01,  6.5804e-02],\n",
       "          [ 6.5554e-02,  1.1244e-01,  1.9969e-01,  1.9164e-01,  9.3151e-02],\n",
       "          [ 7.4799e-02,  1.1324e-01,  1.8063e-01,  1.4845e-01,  2.4932e-02]],\n",
       "\n",
       "         [[-6.3625e-02, -2.0455e-02,  2.5368e-02,  1.0186e-02, -4.3766e-02],\n",
       "          [-4.7827e-02, -2.0817e-02,  2.9596e-02,  1.9007e-02, -4.6581e-02],\n",
       "          [-4.8488e-02, -2.8364e-02,  3.4810e-02,  2.7819e-02, -4.0267e-02],\n",
       "          [-3.9812e-02, -2.0453e-02,  4.7291e-02,  4.0467e-02, -4.4320e-02],\n",
       "          [-4.1408e-02, -2.8891e-02,  2.2081e-02, -7.7125e-03, -1.1660e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1660e+00,  1.1585e+00,  1.1324e+00,  1.0782e+00,  9.7606e-01],\n",
       "          [ 1.2706e+00,  1.2499e+00,  1.2099e+00,  1.1541e+00,  1.0320e+00],\n",
       "          [ 1.1652e+00,  1.1441e+00,  1.1179e+00,  1.0804e+00,  9.8931e-01],\n",
       "          [ 9.7516e-01,  9.4545e-01,  9.2362e-01,  9.3346e-01,  8.8429e-01],\n",
       "          [ 7.2901e-01,  7.5397e-01,  7.8241e-01,  8.0310e-01,  7.5410e-01]],\n",
       "\n",
       "         [[ 1.1436e+00,  1.0903e+00,  1.0482e+00,  1.0083e+00,  9.3385e-01],\n",
       "          [ 1.2229e+00,  1.1699e+00,  1.1185e+00,  1.0733e+00,  9.7012e-01],\n",
       "          [ 1.1001e+00,  1.0590e+00,  1.0233e+00,  9.9225e-01,  9.1553e-01],\n",
       "          [ 8.9707e-01,  8.4919e-01,  8.2567e-01,  8.4645e-01,  8.1426e-01],\n",
       "          [ 6.3323e-01,  6.4121e-01,  6.7502e-01,  7.1560e-01,  6.8594e-01]],\n",
       "\n",
       "         [[ 1.1652e+00,  1.0995e+00,  1.0602e+00,  1.0483e+00,  1.0086e+00],\n",
       "          [ 1.2348e+00,  1.1808e+00,  1.1381e+00,  1.1099e+00,  1.0330e+00],\n",
       "          [ 1.1504e+00,  1.1168e+00,  1.0847e+00,  1.0544e+00,  9.9286e-01],\n",
       "          [ 9.9504e-01,  9.5739e-01,  9.3903e-01,  9.5002e-01,  9.2051e-01],\n",
       "          [ 7.6500e-01,  7.7557e-01,  8.1918e-01,  8.5418e-01,  8.2079e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.0750e-02,  1.1369e-01,  1.2872e-01,  9.8791e-02,  9.0267e-02],\n",
       "          [ 5.9862e-02,  6.5970e-02,  1.5041e-02, -2.7143e-02, -1.2423e-02],\n",
       "          [-7.8704e-03, -2.6436e-02, -9.1405e-02, -1.1269e-01, -1.2434e-01],\n",
       "          [ 1.8540e-02, -2.0097e-02, -9.1709e-02, -1.2169e-01, -1.1066e-01],\n",
       "          [ 1.3625e-01,  9.7779e-02, -1.7805e-04, -3.2207e-02,  3.7616e-02]],\n",
       "\n",
       "         [[-6.8620e-02, -2.0753e-02,  5.3312e-03, -1.5266e-02, -1.0850e-02],\n",
       "          [-7.1606e-02, -3.2681e-02, -5.8968e-02, -8.0174e-02, -4.5025e-02],\n",
       "          [-1.2985e-01, -1.0720e-01, -1.3498e-01, -1.2848e-01, -1.2070e-01],\n",
       "          [-1.0847e-01, -1.0593e-01, -1.3627e-01, -1.3760e-01, -1.1264e-01],\n",
       "          [-8.6345e-03, -1.6554e-02, -8.1057e-02, -8.6546e-02, -5.4323e-03]],\n",
       "\n",
       "         [[ 1.2942e-01,  1.9478e-01,  2.3287e-01,  2.2466e-01,  2.3387e-01],\n",
       "          [ 1.6300e-01,  2.1258e-01,  1.9573e-01,  1.8359e-01,  2.1552e-01],\n",
       "          [ 1.3579e-01,  1.6116e-01,  1.3652e-01,  1.4616e-01,  1.4171e-01],\n",
       "          [ 1.7565e-01,  1.7479e-01,  1.3840e-01,  1.2955e-01,  1.2890e-01],\n",
       "          [ 2.8618e-01,  2.6546e-01,  1.8392e-01,  1.5956e-01,  2.0518e-01]]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv_part[0].conv.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5, 5)\n",
    "A = torch.randn(5, 5)\n",
    "B = torch.randn(5, 5)\n",
    "\n",
    "A.requires_grad = True\n",
    "B.requires_grad = False\n",
    "\n",
    "y = A.mm(B).mm(x)\n",
    "l = y.sum()\n",
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
