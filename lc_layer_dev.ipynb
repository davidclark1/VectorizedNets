{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import vnn\n",
    "import torchvision\n",
    "from imp import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do non-vectorized version first\n",
    "\n",
    "class Local2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, h_in, w_in, stride=1, padding=0, bias=True):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.h_in = h_in\n",
    "        self.w_in = w_in\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.has_bias = bias\n",
    "        h_out = int(np.floor(((h_in + 2*padding - kernel_size)/stride) + 1))\n",
    "        w_out = int(np.floor(((w_in + 2*padding - kernel_size)/stride) + 1))\n",
    "        self.h_out = h_out\n",
    "        self.w_out = w_out\n",
    "        k = in_channels*kernel_size**2\n",
    "        self.weight = nn.Parameter(torch.randn(h_out, w_out, out_channels, in_channels, kernel_size, kernel_size)/np.sqrt(k))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(out_channels, h_out, w_out))\n",
    "        if padding > 0:\n",
    "            self.padder = nn.ZeroPad2d(padding)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        #input = (batch, in_channels, h_in, w_in)\n",
    "        batch_size = input.shape[0]\n",
    "        padded_input = self.padder(input) if self.padding > 0 else input\n",
    "        output = torch.zeros(batch_size, self.out_channels, self.h_out, self.w_out, device=input.device)\n",
    "        for i in range(self.h_out):\n",
    "            for j in range(self.w_out):\n",
    "                i1 = i*self.stride\n",
    "                i2 = i1 + self.kernel_size\n",
    "                j1 = j*self.stride\n",
    "                j2 = j1 + self.kernel_size\n",
    "                input_chunk = padded_input[:, :, i1:i2, j1:j2]\n",
    "                weight_for_chunk = self.weight[i, j] #, :, :, :]\n",
    "                output[:, :, i, j] = torch.einsum(\"oikl,bikl->bo\", weight_for_chunk, input_chunk)\n",
    "        if self.has_bias:\n",
    "            output = output + self.bias[None, :, :, :]\n",
    "        return output\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(Local2d(3, 64, 5, 32, 32, 2, 2),\n",
    "                      nn.ReLU(),\n",
    "                      Local2d(64, 128, 5, 16, 16, 2, 2),\n",
    "                      nn.ReLU(),\n",
    "                      Local2d(128, 256, 3, 8, 8, 2, 1),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Flatten(),\n",
    "                      nn.Linear(4096, 1024),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(1024, 10)).to(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#CIFAR\n",
    "\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "train_set = torchvision.datasets.CIFAR10(\"./data\", train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.CIFAR10(\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "1.4825032312241966\n",
      "0.46608\n",
      "1\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "1.137232693717303\n",
      "0.59414\n",
      "2\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "0.9318077039840581\n",
      "0.6676\n",
      "3\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "0.7528206577996159\n",
      "0.73078\n",
      "4\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "0.585695365200872\n",
      "0.78874\n",
      "5\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "0.43390200666302\n",
      "0.84674\n",
      "6\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "0.3167865096836749\n",
      "0.88792\n",
      "7\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "0.2354684372615936\n",
      "0.91616\n",
      "8\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "0.18606120422291939\n",
      "0.93558\n",
      "9\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3a005bcdab01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mepoch_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "for epoch_idx in range(100):\n",
    "    print(epoch_idx)\n",
    "    epoch_loss = 0.\n",
    "    epoch_correct = 0.\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(batch_idx)\n",
    "        out = model(data.to(0))\n",
    "        loss = loss_fn(out, labels.to(0))\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_correct += (out.argmax(dim=1).cpu() == labels).float().sum().item()\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    print(epoch_loss / (batch_idx + 1))\n",
    "    print(epoch_correct / 50000.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6586"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct = 0\n",
    "total = 0\n",
    "for batch_idx, (data, labels) in enumerate(test_loader):\n",
    "    out = model(data.to(0)).detach()\n",
    "    num_correct += (out.argmax(dim=1).cpu() == labels).int().sum().item()\n",
    "    total += len(data)\n",
    "acc = num_correct / total\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_local(weight, first_layer=False, mono=False):\n",
    "    if mono:\n",
    "        return init_local_mono(weight, first_layer)\n",
    "    weight *= 0.\n",
    "    h_out, w_out, out_channels, in_channels, kernel_size = weight.shape[:5]\n",
    "    f = 1 if first_layer else 0.5\n",
    "    weight.normal_(0., 1./np.sqrt(f * in_channels * kernel_size**2))\n",
    "\n",
    "def init_local_mono(weight, first_layer):\n",
    "    if first_layer:\n",
    "        return init_local_mono_l0(weight)\n",
    "    weight *= 0.\n",
    "    h_out, w_out, out_channels, in_channels, kernel_size = weight.shape[:5]\n",
    "    W = torch.randn(h_out, w_out, out_channels//2, in_channels//2, kernel_size, kernel_size) / np.sqrt(0.25 * in_channels * kernel_size**2)\n",
    "    weight[:, :, ::2, ::2] = F.relu(W)\n",
    "    weight[:, :, ::2, 1::2] = F.relu(-W)\n",
    "    weight[:, :, 1::2, 1::2] = F.relu(W)\n",
    "    weight[:, :, 1::2, ::2] = F.relu(-W)\n",
    "\n",
    "def init_local_mono_l0(weight):\n",
    "    weight *= 0.\n",
    "    h_out, w_out, out_channels, in_channels, kernel_size = weight.shape[:5]\n",
    "    filter_shape_3d = weight.shape[3:]\n",
    "    W = torch.randn((h_out, w_out, out_channels//2,) + filter_shape_3d) / np.sqrt(in_channels * kernel_size**2)\n",
    "    weight[:, :, ::2] = W\n",
    "    weight[:, :, 1::2] = -W\n",
    "\n",
    "class VecLocal2d(nn.Module):\n",
    "    def __init__(self, category_dim, in_channels, out_channels, kernel_size, h_in, w_in,\n",
    "                 stride=1, padding=0,\n",
    "                 mono=False, first_layer=False, device=\"cpu\"):\n",
    "            super().__init__()\n",
    "            self.category_dim = category_dim\n",
    "            self.in_channels = in_channels\n",
    "            self.out_channels = out_channels\n",
    "            self.kernel_size = kernel_size\n",
    "            self.h_in = h_in\n",
    "            self.w_in = w_in\n",
    "            self.mono = mono\n",
    "            self.first_layer = first_layer\n",
    "            self.device = device\n",
    "            self.stride = stride\n",
    "            self.padding = padding\n",
    "            self.lc = Local2d(in_channels, out_channels, kernel_size, h_in, w_in,\n",
    "                              stride=stride, padding=padding, bias=False).to(device)\n",
    "            w_out, h_out = self.lc.w_out, self.lc.h_out\n",
    "            self.bias = nn.Parameter(torch.zeros(category_dim, out_channels, h_out, w_out, device=device))\n",
    "            with torch.no_grad():\n",
    "                init_local(self.lc.weight, first_layer=first_layer, mono=mono)\n",
    "                if first_layer:\n",
    "                    self.lc.weight *= np.sqrt(category_dim)\n",
    "\n",
    "    @property\n",
    "    def weight(self):\n",
    "        return self.lc.weight\n",
    "\n",
    "    def forward(self, input):\n",
    "        #input = (batch_dim, category_dim, channels, width, height)\n",
    "        self.input = input.detach()\n",
    "        batch_size, category_dim = input.shape[:2]\n",
    "        CWH = input.shape[2:]\n",
    "        input_reshaped = input.view((batch_size*category_dim,) + CWH)\n",
    "        output_reshaped = self.lc(input_reshaped)\n",
    "        output = output_reshaped.view((batch_size, category_dim) + output_reshaped.shape[1:])\n",
    "        output = output + self.bias[None, :, :, :, :]\n",
    "        self.mask_shape = (output.shape[0],) + output.shape[2:]\n",
    "        return output\n",
    "    \n",
    "    def post_step_callback(self):\n",
    "        if self.mono and (not self.first_layer):\n",
    "            with torch.no_grad():\n",
    "                #self.conv.weight.clamp_(min=0)\n",
    "                self.lc.weight.abs_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono = False\n",
    "model = nn.Sequential(VecLocal2d(10, 30, 64, 5, 32, 32, 2, 2, first_layer=True, mono=mono),\n",
    "                      vnn.ctReLU(),\n",
    "                      VecLocal2d(10, 64, 128, 5, 16, 16, 2, 2, mono=mono),\n",
    "                      vnn.ctReLU(),\n",
    "                      VecLocal2d(10, 128, 256, 3, 8, 8, 2, 1, mono=mono),\n",
    "                      vnn.ctReLU(),\n",
    "                      vnn.Flatten(),\n",
    "                      vnn.Linear(10, 4096, 1024, mono=mono),\n",
    "                      vnn.tReLU(),\n",
    "                      vnn.Linear(10, 1024, 1, mono=mono)).to(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "Instantiated t with shape (10, 64, 16, 16)\n",
      "Instantiated t with shape (10, 128, 8, 8)\n",
      "Instantiated t with shape (10, 256, 4, 4)\n",
      "Instantiated t with shape (10, 1024)\n",
      "25\n",
      "50\n",
      "75\n",
      "100\n",
      "125\n",
      "150\n",
      "175\n",
      "200\n",
      "225\n",
      "250\n",
      "275\n",
      "300\n",
      "325\n",
      "350\n",
      "375\n",
      "1.53617662389565\n",
      "0.46854\n",
      "1\n",
      "0\n",
      "25\n",
      "50\n",
      "75\n",
      "100\n",
      "125\n",
      "150\n",
      "175\n",
      "200\n",
      "225\n",
      "250\n",
      "275\n",
      "300\n",
      "325\n",
      "350\n",
      "375\n",
      "1.1691053960939197\n",
      "0.59284\n",
      "2\n",
      "0\n",
      "25\n",
      "50\n",
      "75\n",
      "100\n",
      "125\n",
      "150\n",
      "175\n",
      "200\n",
      "225\n",
      "250\n",
      "275\n",
      "300\n",
      "325\n",
      "350\n",
      "375\n",
      "0.9859638319295996\n",
      "0.65764\n",
      "3\n",
      "0\n",
      "25\n",
      "50\n",
      "75\n",
      "100\n",
      "125\n",
      "150\n",
      "175\n",
      "200\n",
      "225\n",
      "250\n",
      "275\n",
      "300\n",
      "325\n",
      "350\n",
      "375\n",
      "0.8380102280460661\n",
      "0.7064\n",
      "4\n",
      "0\n",
      "25\n",
      "50\n",
      "75\n",
      "100\n",
      "125\n",
      "150\n",
      "175\n",
      "200\n",
      "225\n",
      "250\n",
      "275\n",
      "300\n",
      "325\n",
      "350\n",
      "375\n",
      "0.7220104371800142\n",
      "0.74846\n",
      "5\n",
      "0\n",
      "25\n",
      "50\n",
      "75\n",
      "100\n",
      "125\n",
      "150\n",
      "175\n",
      "200\n",
      "225\n",
      "250\n",
      "275\n",
      "300\n",
      "325\n",
      "350\n",
      "375\n",
      "0.6066160157818319\n",
      "0.7893\n",
      "6\n",
      "0\n",
      "25\n",
      "50\n",
      "75\n",
      "100\n",
      "125\n",
      "150\n",
      "175\n",
      "200\n",
      "225\n",
      "250\n",
      "275\n",
      "300\n",
      "325\n",
      "350\n",
      "375\n",
      "0.5325303315506567\n",
      "0.81552\n",
      "7\n",
      "0\n",
      "25\n",
      "50\n",
      "75\n",
      "100\n",
      "125\n",
      "150\n",
      "175\n",
      "200\n",
      "225\n",
      "250\n",
      "275\n",
      "300\n",
      "325\n",
      "350\n",
      "375\n",
      "0.4619803993826937\n",
      "0.84024\n",
      "8\n",
      "0\n",
      "25\n",
      "50\n",
      "75\n",
      "100\n",
      "125\n",
      "150\n",
      "175\n",
      "200\n",
      "225\n",
      "250\n",
      "275\n",
      "300\n",
      "325\n",
      "350\n",
      "375\n",
      "0.41709781851609956\n",
      "0.85584\n",
      "9\n",
      "0\n",
      "25\n",
      "50\n",
      "75\n",
      "100\n",
      "125\n",
      "150\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-245bdd8e3405>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_input_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mepoch_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "for epoch_idx in range(100):\n",
    "    print(epoch_idx)\n",
    "    epoch_loss = 0.\n",
    "    epoch_correct = 0.\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        if batch_idx % 25 == 0:\n",
    "            print(batch_idx)\n",
    "        input = vnn.expand_input_conv(data, 10).to(0)\n",
    "        out = model(input)[..., 0]\n",
    "        loss = loss_fn(out, labels.to(0))\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_correct += (out.argmax(dim=1).cpu() == labels).float().sum().item()\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    print(epoch_loss / (batch_idx + 1))\n",
    "    print(epoch_correct / 50000.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiated t with shape (10, 64, 16, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8995, grad_fn=<StdBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[:3](input).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8682, device='cuda:0', grad_fn=<StdBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
