{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nice_layers as vnn\n",
    "import torchvision\n",
    "from imp import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST \n",
    "\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                                            torchvision.transforms.Lambda(lambda x: torch.flatten(x))])\n",
    "train_set = torchvision.datasets.MNIST(\"./data\", train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.MNIST(\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=200, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=200, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#CIFAR\n",
    "\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "train_set = torchvision.datasets.CIFAR10(\"./data\", train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.CIFAR10(\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonneg = False\n",
    "model = nn.Sequential(vnn.Linear(10, 784*10, 1200, nonneg=False, expanded_input=True),\n",
    "                      vnn.tReLU(),\n",
    "                      vnn.Linear(10, 1200, 600, nonneg=nonneg),\n",
    "                      vnn.tReLU(),\n",
    "                      vnn.Linear(10, 600, 1, nonneg=nonneg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update utilty\n",
    "def set_model_grads(model, output, labels):\n",
    "    targets = torch.eye(10, device=labels.device)[labels]\n",
    "    output_error = F.softmax(output, dim=1) - targets\n",
    "    for i in range(len(model)):\n",
    "        layer = model[i]\n",
    "        if type(layer) in (vnn.Conv2d, vnn.Linear):\n",
    "            if (i == len(model) - 1) or (type(model[i+1]) not in (vnn.ReLU, vnn.tReLU)):\n",
    "                mask = torch.ones(layer.mask_shape, device=output.device)\n",
    "            else:\n",
    "                mask = model[i+1].mask\n",
    "            layer.set_grad(mask, output_error)\n",
    "    nans = np.any([torch.any(torch.isnan(p)).item() for p in model.parameters()])\n",
    "    if nans:\n",
    "        print(\"Warning: NAN!\")\n",
    "            \n",
    "            \n",
    "def expand_input(input, category_dim):\n",
    "    batch_dim, input_dim = input.shape\n",
    "    expanded_input = torch.zeros(batch_dim, category_dim, category_dim*input_dim)\n",
    "    for i in range(category_dim):\n",
    "        expanded_input[:, i, i*input_dim:(i+1)*input_dim] = input\n",
    "    return expanded_input\n",
    "\n",
    "def expand_input_conv(input, category_dim):\n",
    "    #input = (batch, channels, width, height)\n",
    "    batch_size, in_channels = input.shape[:2]\n",
    "    expanded_input = torch.zeros((batch_size, category_dim, in_channels*category_dim) + input.shape[2:])\n",
    "    for i in range(category_dim):\n",
    "        expanded_input[:, i, i*in_channels:(i+1)*in_channels] = input\n",
    "    return expanded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Instantiated t with shape (10, 1200)\n",
      "Instantiated t with shape (10, 600)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ef8c464d49f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mepoch_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "opt = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "for epoch_idx in range(1000):\n",
    "    print(epoch_idx)\n",
    "    epoch_loss = 0.\n",
    "    epoch_correct = 0.\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        input = expand_input(data, 10)\n",
    "        with torch.no_grad():\n",
    "            out = model(input)[..., 0]\n",
    "        epoch_loss += loss_fn(out, labels).item()\n",
    "        epoch_correct += (out.argmax(dim=1) == labels).float().sum()\n",
    "        opt.zero_grad()\n",
    "        set_model_grads(model, out, labels)\n",
    "        opt.step()\n",
    "        for layer in model: layer.post_step_callback()\n",
    "    print(epoch_loss / (batch_idx + 1))\n",
    "    print(epoch_correct / 60000.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9174"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct = 0\n",
    "for batch_idx, (data, labels) in enumerate(test_loader):\n",
    "    input = expand_input(data, 10)\n",
    "    with torch.no_grad():\n",
    "        out = model.forward(input)[..., 0]\n",
    "    num_correct += (out.argmax(dim=1) == labels).int().sum().item()\n",
    "acc = num_correct / 10000.\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_conv_l0(weight):\n",
    "    out_channels, in_channels = weight.shape[:2]\n",
    "    kernel_size = weight.shape[-1]\n",
    "    W_shape = weight.shape[1:]\n",
    "    for i in range(out_channels // 2):\n",
    "        W = torch.randn(W_shape) * 1./np.sqrt((in_channels/10.) * kernel_size**2)\n",
    "        weight[2*i] = W\n",
    "        weight[2*i + 1] = -W\n",
    "\n",
    "def init_conv(weight):\n",
    "    out_channels, in_channels = weight.shape[:2]\n",
    "    kernel_size = weight.shape[-1]\n",
    "    W_shape = weight.shape[2:]\n",
    "    for i in range(out_channels // 2):\n",
    "        for j in range(in_channels // 2):\n",
    "            W = torch.randn(W_shape) * 1./np.sqrt(0.25*in_channels * kernel_size**2)\n",
    "            i1, i2 = i*2, i*2 + 1\n",
    "            j1, j2 = j*2, j*2 + 1\n",
    "            #if np.random.rand() < 0.5:\n",
    "            weight[i1, j1] = F.relu(W)\n",
    "            weight[i2, j2] = F.relu(W)\n",
    "            #else:\n",
    "            weight[i1, j2] = F.relu(-W)\n",
    "            weight[i2, j1] = F.relu(-W)\n",
    "                \n",
    "def init_t(t):\n",
    "    features = t.shape[1]\n",
    "    for i in range(features // 2):\n",
    "        t[:, 2*i + 1] = -t[:, 2*i]\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiated t with shape (10, 192, 16, 16)\n",
      "Instantiated t with shape (10, 192, 5, 5)\n",
      "Instantiated t with shape (10, 192, 1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  7.,  20.,  96., 191., 366., 364., 150.,  60.,  23.,   3.]),\n",
       " array([-1.9084553 , -1.5186098 , -1.1287644 , -0.7389189 , -0.34907347,\n",
       "         0.04077196,  0.4306174 ,  0.8204628 ,  1.2103083 ,  1.6001537 ,\n",
       "         1.9899992 ], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reload(vnn)\n",
    "nonneg = True\n",
    "model = nn.Sequential(vnn.Conv2d(10, 30, 96*2, 2, stride=2, nonneg=False, expanded_input=True),\n",
    "                      vnn.tReLU(),\n",
    "                      vnn.Conv2d(10, 96*2, 96*2, 3, stride=3, nonneg=nonneg, expanded_input=False),\n",
    "                      vnn.tReLU(),\n",
    "                      vnn.Conv2d(10, 96*2, 96*2, 3, stride=3, nonneg=nonneg, expanded_input=False),\n",
    "                      vnn.tReLU(),\n",
    "                      vnn.Flatten(),\n",
    "                      vnn.Linear(10, 96*2, 1, nonneg=nonneg)).to(0)\n",
    "\n",
    "input = expand_input_conv(data, 10).to(0)\n",
    "out = model(input)\n",
    "\n",
    "with torch.no_grad():\n",
    "    init_conv_l0(model[0].conv.weight)\n",
    "    init_t(model[1].t)\n",
    "    init_conv(model[2].conv.weight)\n",
    "    init_t(model[3].t)\n",
    "    init_conv(model[4].conv.weight)\n",
    "    init_t(model[5].t)\n",
    "    W_last = torch.abs(torch.randn(96) / np.sqrt(192. * 0.25))\n",
    "    model[7].weight *= 0.\n",
    "    model[7].weight[0, ::2] = W_last\n",
    "    #model[7].weight[0, 1::2] = W_last\n",
    "    #model[0].conv.weight *= 0.5\n",
    "    #model[2].conv.weight *= 0.5\n",
    "    #model[4].conv.weight *= 0.5\n",
    "\n",
    "input = expand_input_conv(data, 10).to(0)\n",
    "out = model(input)\n",
    "plt.hist(out.cpu().detach().numpy().flatten())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -5.1821e-02,\n",
       "         5.1821e-02,  2.7705e-01, -2.7705e-01, -0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,  4.4373e-02,\n",
       "        -4.4373e-02,  1.5393e-02, -1.5393e-02,  4.6490e-01, -4.6490e-01,\n",
       "         1.3764e-02, -1.3764e-02,  1.4162e-01, -1.4162e-01, -0.0000e+00,\n",
       "         0.0000e+00, -0.0000e+00,  0.0000e+00, -2.0604e-01,  2.0604e-01,\n",
       "         6.8027e-02, -6.8027e-02, -1.8308e-01,  1.8308e-01, -1.3404e-01,\n",
       "         1.3404e-01,  0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "        -1.5464e-01,  1.5464e-01,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "        -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "        -0.0000e+00,  0.0000e+00, -7.0340e-02,  7.0340e-02, -0.0000e+00,\n",
       "         0.0000e+00, -6.2558e-02,  6.2558e-02,  1.8579e-02, -1.8579e-02,\n",
       "         2.0959e-01, -2.0959e-01,  1.8493e-01, -1.8493e-01, -3.4754e-01,\n",
       "         3.4754e-01,  3.9574e-01, -3.9574e-01,  1.0964e-01, -1.0964e-01,\n",
       "         1.5949e-01, -1.5949e-01, -4.2179e-01,  4.2179e-01,  0.0000e+00,\n",
       "        -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "        -5.1773e-01,  5.1773e-01, -3.5051e-01,  3.5051e-01,  4.6644e-01,\n",
       "        -4.6644e-01,  2.5149e-01, -2.5149e-01,  0.0000e+00, -0.0000e+00,\n",
       "         5.7840e-01, -5.7840e-01, -0.0000e+00,  0.0000e+00,  1.0497e-01,\n",
       "        -1.0497e-01, -4.1699e-02,  4.1699e-02,  2.3858e-02, -2.3858e-02,\n",
       "        -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00, -4.1789e-01,\n",
       "         4.1789e-01, -4.3146e-04,  4.3140e-04,  5.8719e-01, -5.8719e-01,\n",
       "        -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         0.0000e+00,  4.2499e-01, -4.2499e-01,  0.0000e+00, -0.0000e+00,\n",
       "        -6.2261e-01,  6.2261e-01, -0.0000e+00,  0.0000e+00, -1.9268e-02,\n",
       "         1.9268e-02, -3.0039e-02,  3.0039e-02,  0.0000e+00, -0.0000e+00,\n",
       "         0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,  1.8570e-02,\n",
       "        -1.8570e-02, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "         0.0000e+00, -0.0000e+00,  9.7188e-02, -9.7188e-02, -0.0000e+00,\n",
       "         0.0000e+00, -2.7465e-01,  2.7465e-01, -0.0000e+00,  0.0000e+00,\n",
       "        -3.7319e-01,  3.7319e-01, -2.3298e-01,  2.3298e-01, -0.0000e+00,\n",
       "         0.0000e+00, -4.8102e-01,  4.8102e-01,  0.0000e+00, -0.0000e+00,\n",
       "        -2.4561e-01,  2.4561e-01, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        -0.0000e+00, -0.0000e+00,  0.0000e+00, -3.1742e-01,  3.1742e-01,\n",
       "         4.9629e-02, -4.9629e-02, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "         0.0000e+00, -4.7797e-02,  4.7797e-02, -1.1199e-01,  1.1199e-01,\n",
       "        -1.3692e-01,  1.3692e-01, -1.8380e-01,  1.8380e-01, -1.2535e-01,\n",
       "         1.2535e-01,  3.2746e-01, -3.2746e-01,  7.3667e-01, -7.3667e-01,\n",
       "        -2.6123e-01,  2.6123e-01], device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = expand_input_conv(data, 10).to(0)\n",
    "model[:7](input)[0, 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "2.0907916781847433\n",
      "0.248\n",
      "1\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "2.0596694927996078\n",
      "0.26162\n",
      "2\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "2.039137040562642\n",
      "0.27082\n",
      "3\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "2.0258365250609414\n",
      "0.27396\n",
      "4\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "2.018586888642567\n",
      "0.27696\n",
      "5\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "2.011790730459306\n",
      "0.27908\n",
      "6\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "2.0072065225952422\n",
      "0.28542\n",
      "7\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "1.999770408701104\n",
      "0.28518\n",
      "8\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "1.994799063943536\n",
      "0.28816\n",
      "9\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "1.9896031508360372\n",
      "0.28992\n",
      "10\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "1.9834656715393066\n",
      "0.29156\n",
      "11\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "1.9774582230526467\n",
      "0.2909\n",
      "12\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "1.9729847932410667\n",
      "0.29148\n",
      "13\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "1.9673175433712542\n",
      "0.29378\n",
      "14\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "1.9628477715470296\n",
      "0.29378\n",
      "15\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "1.9623772107121888\n",
      "0.29324\n",
      "16\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "1.9601445045617536\n",
      "0.2932\n",
      "17\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "1.9596500689416285\n",
      "0.29304\n",
      "18\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-390-f361f46b7ac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_input_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "opt = optim.SGD(model.parameters(), lr=1e-3, momentum=0.4)\n",
    "\n",
    "for epoch_idx in range(1000):\n",
    "    print(epoch_idx)\n",
    "    epoch_loss = 0.\n",
    "    epoch_correct = 0.\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(batch_idx)\n",
    "        input = expand_input_conv(data, 10).to(0)\n",
    "        with torch.no_grad():\n",
    "            out = model(input)[..., 0]\n",
    "        epoch_loss += loss_fn(out, labels.to(0)).item()\n",
    "        c = (out.argmax(dim=1).cpu() == labels).float().sum().item()\n",
    "        epoch_correct += c\n",
    "        opt.zero_grad()\n",
    "        set_model_grads(model, out, labels.to(0))\n",
    "        opt.step()\n",
    "        for layer in model: layer.post_step_callback()\n",
    "    print(epoch_loss / (batch_idx + 1))\n",
    "    print(epoch_correct / 50000.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = expand_input_conv(data, 10).to(0)\n",
    "with torch.no_grad():\n",
    "    out = model(input)[..., 0]\n",
    "opt.zero_grad()\n",
    "set_model_grads(model, out, labels.to(0))\n",
    "G1 = model[0].conv.weight.grad.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = expand_input_conv(data, 10).to(0)\n",
    "out = model(input)[..., 0]\n",
    "loss = loss_fn(out, labels.to(0))\n",
    "opt.zero_grad()\n",
    "loss.backward()\n",
    "G2 = model[0].conv.weight.grad.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8082992550571558, 0.0)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr(G1.flatten(), G2.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fe6467b1970>"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(G1.flatten(), G2.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinregressResult(slope=2.4107578671313687, intercept=-2.459332929029321e-10, rvalue=0.8082992550571554, pvalue=0.0, stderr=0.011569273263664531)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linregress(G1.flatten(), G2.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269.32332577450893"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1./0.003713009250588456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
