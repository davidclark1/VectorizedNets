{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nice_layers as vnn\n",
    "import torchvision\n",
    "from imp import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST \n",
    "\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                                            torchvision.transforms.Lambda(lambda x: torch.flatten(x))])\n",
    "train_set = torchvision.datasets.MNIST(\"./data\", train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.MNIST(\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=200, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=200, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#CIFAR\n",
    "\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "train_set = torchvision.datasets.CIFAR10(\"./data\", train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.CIFAR10(\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonneg = False\n",
    "model = nn.Sequential(vnn.Linear(10, 784*10, 1200, nonneg=False, expanded_input=True),\n",
    "                      vnn.tReLU(),\n",
    "                      vnn.Linear(10, 1200, 600, nonneg=nonneg),\n",
    "                      vnn.tReLU(),\n",
    "                      vnn.Linear(10, 600, 1, nonneg=nonneg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update utilty\n",
    "def set_model_grads(model, output, labels):\n",
    "    targets = torch.eye(10, device=labels.device)[labels]\n",
    "    output_error = F.softmax(output, dim=1) - targets\n",
    "    for i in range(len(model)):\n",
    "        layer = model[i]\n",
    "        if type(layer) in (vnn.Conv2d, vnn.Linear):\n",
    "            if (i == len(model) - 1) or (type(model[i+1]) not in (vnn.ReLU, vnn.tReLU)):\n",
    "                mask = torch.ones(layer.mask_shape, device=output.device)\n",
    "            else:\n",
    "                mask = model[i+1].mask\n",
    "            layer.set_grad(mask, output_error)\n",
    "    nans = np.any([torch.any(torch.isnan(p)).item() for p in model.parameters()])\n",
    "    if nans:\n",
    "        print(\"Warning: NAN!\")\n",
    "            \n",
    "            \n",
    "def expand_input(input, category_dim):\n",
    "    batch_dim, input_dim = input.shape\n",
    "    expanded_input = torch.zeros(batch_dim, category_dim, category_dim*input_dim)\n",
    "    for i in range(category_dim):\n",
    "        expanded_input[:, i, i*input_dim:(i+1)*input_dim] = input\n",
    "    return expanded_input\n",
    "\n",
    "def expand_input_conv(input, category_dim):\n",
    "    #input = (batch, channels, width, height)\n",
    "    batch_size, in_channels = input.shape[:2]\n",
    "    expanded_input = torch.zeros((batch_size, category_dim, in_channels*category_dim) + input.shape[2:])\n",
    "    for i in range(category_dim):\n",
    "        expanded_input[:, i, i*in_channels:(i+1)*in_channels] = input\n",
    "    return expanded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Instantiated t with shape (10, 1200)\n",
      "Instantiated t with shape (10, 600)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ef8c464d49f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mepoch_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "opt = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "for epoch_idx in range(1000):\n",
    "    print(epoch_idx)\n",
    "    epoch_loss = 0.\n",
    "    epoch_correct = 0.\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        input = expand_input(data, 10)\n",
    "        with torch.no_grad():\n",
    "            out = model(input)[..., 0]\n",
    "        epoch_loss += loss_fn(out, labels).item()\n",
    "        epoch_correct += (out.argmax(dim=1) == labels).float().sum()\n",
    "        opt.zero_grad()\n",
    "        set_model_grads(model, out, labels)\n",
    "        opt.step()\n",
    "        for layer in model: layer.post_step_callback()\n",
    "    print(epoch_loss / (batch_idx + 1))\n",
    "    print(epoch_correct / 60000.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9174"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct = 0\n",
    "for batch_idx, (data, labels) in enumerate(test_loader):\n",
    "    input = expand_input(data, 10)\n",
    "    with torch.no_grad():\n",
    "        out = model.forward(input)[..., 0]\n",
    "    num_correct += (out.argmax(dim=1) == labels).int().sum().item()\n",
    "acc = num_correct / 10000.\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_conv_l0(weight, category_dim=1):\n",
    "    out_channels, in_channels, kernel_size = weight.shape[:3] #assumes square kernel\n",
    "    W_shape = weight.shape[1:]\n",
    "    for i in range(out_channels // 2):\n",
    "        W = torch.randn(W_shape) / np.sqrt((in_channels / category_dim) * kernel_size**2)\n",
    "        weight[2*i] = W\n",
    "        weight[2*i + 1] = -W\n",
    "\n",
    "def init_conv(weight):\n",
    "    out_channels, in_channels, kernel_size = weight.shape[:3] #assumes square kernel\n",
    "    W_shape = weight.shape[2:]\n",
    "    for i in range(out_channels // 2):\n",
    "        for j in range(in_channels // 2):\n",
    "            W = torch.randn(W_shape) / np.sqrt(0.25 * in_channels * kernel_size**2)\n",
    "            i1, i2 = i*2, i*2 + 1\n",
    "            j1, j2 = j*2, j*2 + 1\n",
    "            weight[i1, j1] = F.relu(W)\n",
    "            weight[i2, j2] = F.relu(W)\n",
    "            weight[i1, j2] = F.relu(-W)\n",
    "            weight[i2, j1] = F.relu(-W)\n",
    "                \n",
    "def init_t(t):\n",
    "    features = t.shape[1]\n",
    "    for i in range(features // 2):\n",
    "        t[:, 2*i + 1] = -t[:, 2*i]\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiated t with shape (10, 96, 14, 14)\n",
      "Instantiated t with shape (10, 96, 6, 6)\n",
      "Instantiated t with shape (10, 96, 4, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.039878096"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reload(vnn)\n",
    "nonneg = False\n",
    "model = nn.Sequential(vnn.Conv2d(10, 30, 96, 5, stride=2, nonneg=False, expanded_input=True),\n",
    "                      vnn.tReLU(),\n",
    "                      vnn.Conv2d(10, 96, 96, 3, stride=2, nonneg=nonneg, expanded_input=False),\n",
    "                      vnn.tReLU(),\n",
    "                      vnn.Conv2d(10, 96, 96, 3, stride=1, nonneg=nonneg, expanded_input=False),\n",
    "                      vnn.tReLU(),\n",
    "                      vnn.Flatten(),\n",
    "                      vnn.Linear(10, 1536, 1, nonneg=nonneg)).to(0)\n",
    "\n",
    "data = torch.randn(500, 3, 32, 32)\n",
    "input = expand_input_conv(data, 10).to(0)\n",
    "out = model(input)\n",
    "\n",
    "\"\"\"\n",
    "with torch.no_grad():\n",
    "    init_conv_l0(model[0].conv.weight, category_dim=10)\n",
    "    init_t(model[1].t)\n",
    "    init_conv(model[2].conv.weight)\n",
    "    init_t(model[3].t)\n",
    "    init_conv(model[4].conv.weight)\n",
    "    init_t(model[5].t)\n",
    "    W_last = (1./0.8) * torch.randn(1536 // 2) / np.sqrt(0.25 * 1536)\n",
    "    model[7].weight *= 0.\n",
    "    model[7].weight[0, ::2] = F.relu(W_last)\n",
    "    model[7].weight[0, 1::2] = F.relu(-W_last)\n",
    "    \n",
    "\n",
    "out = model(input)\n",
    "vals = out.cpu().detach().numpy().flatten()\n",
    "\n",
    "plt.hist(vals, bins=50, range=(-4, 4))\n",
    "vals.std()\n",
    "\"\"\"\n",
    "\n",
    "vals = out.cpu().detach().numpy().flatten()\n",
    "plt.hist(vals, bins=50, range=(-4, 4))\n",
    "vals.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 10, 1536])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[:7](input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "1.9368599012989522\n",
      "0.29758\n",
      "1\n",
      "0\n",
      "100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-316-640d2abd7e69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mepoch_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3) #, momentum=0.0)\n",
    "\n",
    "for epoch_idx in range(1000):\n",
    "    print(epoch_idx)\n",
    "    epoch_loss = 0.\n",
    "    epoch_correct = 0.\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(batch_idx)\n",
    "        input = expand_input_conv(data, 10).to(0)\n",
    "        with torch.no_grad():\n",
    "            out = model(input)[..., 0]\n",
    "        epoch_loss += loss_fn(out, labels.to(0)).item()\n",
    "        c = (out.argmax(dim=1).cpu() == labels).float().sum().item()\n",
    "        epoch_correct += c\n",
    "        opt.zero_grad()\n",
    "        set_model_grads(model, out, labels.to(0))\n",
    "        opt.step()\n",
    "        for layer in model: layer.post_step_callback()\n",
    "    print(epoch_loss / (batch_idx + 1))\n",
    "    print(epoch_correct / 50000.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "#data = torch.randn(500, 3, 32, 32)\n",
    "#labels = torch.randint(0, 10, (len(data),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = expand_input_conv(data, 10).to(0)\n",
    "with torch.no_grad():\n",
    "    out = model(input)[..., 0]\n",
    "opt.zero_grad()\n",
    "set_model_grads(model, out, labels.to(0))\n",
    "G1 = model[0].conv.weight.grad.detach().cpu().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = expand_input_conv(data, 10).to(0)\n",
    "out = model(input)[..., 0]\n",
    "loss = loss_fn(out, labels.to(0))\n",
    "opt.zero_grad()\n",
    "loss.backward()\n",
    "G2 = model[0].conv.weight.grad.detach().cpu().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((72000,), (72000,))"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G1.shape, G2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8984318343042683, 0.0)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr(G1.flatten(), G2.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f69d92c7be0>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(G1, G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinregressResult(slope=0.08156824135508328, intercept=-5.607639407292361e-06, rvalue=0.4925036566970165, pvalue=0.0, stderr=0.0005004936230648975)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linregress(G1, G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5515, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[4].conv.weight.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8324, 0.5145, 0.7072, 0.6131, 0.2930, 0.6666, 0.8563, 0.6071, 0.0702,\n",
       "         0.4819],\n",
       "        [0.8280, 0.7013, 0.8857, 0.9641, 0.6493, 0.2816, 0.5505, 0.6273, 0.9735,\n",
       "         0.0324],\n",
       "        [0.9987, 0.8994, 0.9916, 0.4456, 0.4005, 0.8194, 0.1888, 0.9755, 0.1831,\n",
       "         0.2050],\n",
       "        [0.7984, 0.5835, 0.5951, 0.1926, 0.2305, 0.6204, 0.6890, 0.8318, 0.0459,\n",
       "         0.8267],\n",
       "        [0.1242, 0.4014, 0.5945, 0.3053, 0.3321, 0.7460, 0.0017, 0.4221, 0.6020,\n",
       "         0.2783],\n",
       "        [0.7828, 0.7918, 0.3018, 0.8300, 0.7986, 0.5386, 0.0527, 0.9898, 0.1681,\n",
       "         0.7082],\n",
       "        [0.3646, 0.2159, 0.8874, 0.2022, 0.5821, 0.0611, 0.1538, 0.1806, 0.3488,\n",
       "         0.4989],\n",
       "        [0.0792, 0.7856, 0.4457, 0.7969, 0.8331, 0.3158, 0.2609, 0.6558, 0.5551,\n",
       "         0.5193],\n",
       "        [0.3055, 0.1713, 0.2926, 0.4771, 0.5391, 0.6197, 0.8115, 0.7796, 0.1753,\n",
       "         0.1136],\n",
       "        [0.7704, 0.6856, 0.4499, 0.1575, 0.6494, 0.0165, 0.0954, 0.5803, 0.0557,\n",
       "         0.5830]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand((10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1082e+02, -6.8048e+01, -5.7649e+01,  ..., -1.3390e+02,\n",
       "         -1.7740e+02,  6.0456e+01],\n",
       "        [ 1.5397e+02,  7.4208e+01, -3.8442e+01,  ...,  6.2617e+01,\n",
       "         -1.1558e+01,  8.4694e+01],\n",
       "        [ 8.2938e+01, -2.2227e+02,  3.0374e+00,  ..., -1.2173e+02,\n",
       "         -1.4313e+02, -2.8173e+01],\n",
       "        ...,\n",
       "        [ 8.9641e+00,  5.3192e+01, -1.9919e-01,  ...,  3.5858e+01,\n",
       "         -2.2046e+02,  9.9749e+01],\n",
       "        [-1.6191e+01, -1.2757e+02,  3.6809e+01,  ..., -1.1954e+02,\n",
       "          3.9169e+01,  1.8366e+02],\n",
       "        [ 3.1493e+01, -1.2484e+02, -6.4529e+00,  ...,  5.8008e+01,\n",
       "          1.7060e+01,  5.4349e+01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(50, 50)\n",
    "a.normal_(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(102.0952)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
